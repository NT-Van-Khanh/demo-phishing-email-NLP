{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "eY1C50dpJzKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mailbox\n",
        "import email\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# import gensim\n",
        "import gensim.parsing.preprocessing as preprocessing\n",
        "import gensim.corpora as corpora\n",
        "import gensim.models as models\n",
        "# from gensim.models import Word2Vec\n",
        "# from gensim.models import LdaMulticore\n",
        "\n"
      ],
      "metadata": {
        "id": "je-Elkn0J3nU",
        "outputId": "c35a22a4-629a-46b7-8dca-7acb645edfdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "YraJJFnTQwvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Email"
      ],
      "metadata": {
        "id": "5ZEwrhkOWzXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions: Extract email from .mbox file and .eml file\n"
      ],
      "metadata": {
        "id": "YBf_LlOI-Cnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_emails_from_mbox(mbox_file_name):\n",
        "  messages=[]\n",
        "  try:\n",
        "    mbox = mailbox.mbox(mbox_file_name)\n",
        "    for message in mbox:\n",
        "      messages.append(message)\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File not found: {mbox_file_name}\")\n",
        "  return messages\n",
        "\n",
        "\n",
        "def extract_email_from_eml(eml_file_name):\n",
        "  email_message=None\n",
        "  try:\n",
        "      with open(eml_file_name, \"r\") as email_file:\n",
        "          email_message = email.message_from_file(email_file)\n",
        "  except FileNotFoundError:\n",
        "      print(f\"File not found: {eml_file_name}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "  return email_message\n",
        "\n",
        "#From:https://stackoverflow.com/questions/7166922/extracting-the-body-of-an-email-from-mbox-file-decoding-it-to-plain-text-regard"
      ],
      "metadata": {
        "id": "M0vGJHcsbPak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions: Extract component of email"
      ],
      "metadata": {
        "id": "mJYw16uQIDEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sender_email(email_message):\n",
        "  return email_message.get(\"From\")\n",
        "\n",
        "\n",
        "def extract_subject_email(email_message):\n",
        "  return email_message.get(\"Subject\")\n",
        "\n",
        "\n",
        "def extract_content_email(email_message):\n",
        "  body = None\n",
        "  if(email_message.is_multipart()):\n",
        "    for part in email_message.walk():\n",
        "      if(part.is_multipart()):\n",
        "        for subpart in part.walk():\n",
        "          if(subpart.get_content_type() == \"text/plain\"):\n",
        "            body = subpart.get_payload(decode=True)\n",
        "          # elif(subpart.get_content_type() == \"text/html\"):\n",
        "          #   body = subpart.get_payload(decode=True)\n",
        "      elif(part.get_content_type() == \"text/plain\"):\n",
        "        body = part.get_payload(decode=True)\n",
        "  else:\n",
        "    body = email_message.get_payload(decode=True)\n",
        "  if(body is not None):\n",
        "    #chuyển dữ liệu dạng byte string sang string (utf-8)\n",
        "    body=body.decode('utf-8')\n",
        "  return body"
      ],
      "metadata": {
        "id": "sBT5Yl7GTPfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process: Extract phishing emails"
      ],
      "metadata": {
        "id": "HtC14PZmJG_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phishing_message_bodies = []\n",
        "\n",
        "\n",
        "phishing_messages = extract_emails_from_mbox(\"/content/emails-enron-legal-mails.mbox\")\n",
        "for message in phishing_messages:\n",
        "  body=extract_content_email(message)\n",
        "  if (body is not None and body.strip()):\n",
        "    phishing_message_bodies.append(body)\n",
        "    #print(body)\n",
        "    #print(body).decode('utf-8')\n",
        "\n",
        "print(len(phishing_message_bodies))\n",
        "print(len(phishing_messages))"
      ],
      "metadata": {
        "id": "b2FoHAWSGrUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process: Extract benign emails"
      ],
      "metadata": {
        "id": "dYVDbnwbEUie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benign_message_bodies = []\n",
        "\n",
        "\n",
        "benign_messages = extract_emails_from_mbox(\"/content/emails-enron-ham.mbox\")\n",
        "for message in benign_messages:\n",
        "  body=extract_content_email(message)\n",
        "  if (body is not None and body.strip()):\n",
        "    benign_message_bodies.append(body)\n",
        "\n",
        "print(len(benign_message_bodies))\n",
        "print(len(benign_messages))"
      ],
      "metadata": {
        "id": "pmmlNwehETr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ===TEST==="
      ],
      "metadata": {
        "id": "VQOB1m2h1Tug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msg = extract_email_from_eml(\"/content/sample1.eml\")\n",
        "messages = extract_emails_from_mbox(\"/emails-enron-legal-mails.mbox\")\n",
        "if(msg):\n",
        "  print(extract_sender_email(msg))\n",
        "  print(extract_subject_email(msg))\n",
        "  print(extract_content_email(msg))"
      ],
      "metadata": {
        "id": "LzTM6l8fKWtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(phishing_messages[0])\n",
        "print(phishing_message_bodies[0])"
      ],
      "metadata": {
        "id": "ZFt1xuQ61WBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(benign_messages[0])\n",
        "print(benign_message_bodies[0])"
      ],
      "metadata": {
        "id": "3t1IbwnB1Z2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple preprocessing"
      ],
      "metadata": {
        "id": "jdd-9_Ye04iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom stop words and preprocessing filters\n",
        "\n",
        "stopWords = nltk.corpus.stopwords\n",
        "stopWords = stopWords.words(\"english\")\n",
        "stopWords.extend([\"nbsp\", \"font\", \"sans\", \"serif\", \"bold\", \"arial\", \"verdana\", \"helvetica\", \"http\", \"https\", \"www\", \"html\", \"enron\", \"margin\", \"spamassassin\"])\n",
        "\n",
        "def remove_custom_stopwords(p):\n",
        "    return preprocessing.remove_stopwords(p, stopwords=stopWords)\n",
        "\n",
        "CUSTOM_FILTERS = [lambda x: x.lower(), preprocessing.strip_tags, preprocessing.strip_punctuation,\n",
        "                  preprocessing.strip_multiple_whitespaces, preprocessing.strip_numeric, remove_custom_stopwords,\n",
        "                  preprocessing.remove_stopwords, preprocessing.strip_short, preprocessing.stem_text]\n"
      ],
      "metadata": {
        "id": "ZftALxyg079z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing phishing message bodies\n",
        "phishing_preprocessed = []\n",
        "\n",
        "for message in phishing_message_bodies:\n",
        "  message_preprocessed = preprocessing.preprocess_string(message,filters = CUSTOM_FILTERS)\n",
        "  phishing_preprocessed.append(message_preprocessed)\n",
        "\n",
        "print(len(phishing_preprocessed))"
      ],
      "metadata": {
        "id": "MkbJl5lZ0_SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing benign message bodies\n",
        "benign_preprocessed = []\n",
        "\n",
        "for message in benign_message_bodies:\n",
        "  message_preprocessed = preprocessing.preprocess_string(message,filters = CUSTOM_FILTERS)\n",
        "  benign_preprocessed.append(message_preprocessed)\n",
        "\n",
        "print(len(benign_preprocessed))"
      ],
      "metadata": {
        "id": "t2FnvYnt1BWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "print(phishing_preprocessed[1])"
      ],
      "metadata": {
        "id": "_0U5tciJ1DKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec Embedding\n"
      ],
      "metadata": {
        "id": "wtANJcvfjMD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on all messages\n",
        "model = models.Word2Vec(phishing_preprocessed + benign_preprocessed, vector_size=100, min_count=1, workers=3, window=5)\n",
        "\n",
        "#From: https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/"
      ],
      "metadata": {
        "id": "kRgK9ldSkCtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"dollar\", topn=20)"
      ],
      "metadata": {
        "id": "3e4GPHLjluvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"dollar\"]"
      ],
      "metadata": {
        "id": "ykaw9PxJlvup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA Topic Modeling"
      ],
      "metadata": {
        "id": "j8sFzX6jU8mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init the number of topics"
      ],
      "metadata": {
        "id": "ZpBNSKMUWhQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numTopics = 1024"
      ],
      "metadata": {
        "id": "_d1CZXaGVRy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dictionary and corpus"
      ],
      "metadata": {
        "id": "aguwb1mdVu4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message_preprocessed = phishing_preprocessed + benign_preprocessed\n",
        "\n",
        "dictionary = corpora.Dictionary(message_preprocessed)\n",
        "corpus = [dictionary.doc2bow(text) for text in message_preprocessed]"
      ],
      "metadata": {
        "id": "r6qsxlGvVccA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Create LDA model"
      ],
      "metadata": {
        "id": "efVePDN9VySO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LDA_model = models.LdaMulticore(corpus=corpus, num_topics=numTopics, id2word=dictionary)"
      ],
      "metadata": {
        "id": "TbqOjNTPXTVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "# Print keyword for the topics\n",
        "print(LDA_model.print_topics())"
      ],
      "metadata": {
        "id": "SNJqzs9mZ3wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Doc2Vec"
      ],
      "metadata": {
        "id": "K-V4GinQabbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_data = [models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(message_preprocessed)]"
      ],
      "metadata": {
        "id": "aC8vWlZ3aezK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Khởi tạo và huấn luyện trực tiếp\n",
        "doc2vec_model = models.Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4)\n",
        "\n",
        "#Tách khởi tạo và huấn luyện\n",
        "# doc2vec_model = models.Doc2Vec(tagged_data, vector_size=100, min_count=1, epochs=10)\n",
        "# doc2vec_model.build_vocab(tagged_data)\n",
        "# doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)"
      ],
      "metadata": {
        "id": "5_JOKTTzfDMP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}